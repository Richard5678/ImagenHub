# ImagenHub
[![arXiv](https://img.shields.io/badge/arXiv-2310.01596-b31b1b.svg)](https://arxiv.org/abs/2310.01596)

![](https://github.com/TIGER-AI-Lab/ImagenHub/blob/gh-pages/static/images/banner.png)

ImagenHub is a one-stop library to standardize the inference and evaluation of all the conditional image generation models. Read more on the [Project Page](https://tiger-ai-lab.github.io/ImagenHub/)
* We define 7 prominent tasks and curate 7 high-quality evaluation datasets for each task. 
* We built a unified inference pipeline to ensure fair comparison. We currently support around 30 models.
* We designed two human evaluation scores, i.e. Semantic Consistency and Perceptual Quality, along with comprehensive guidelines to evaluate generated images. 
* We provide code for visualization, autometrics and Amazon mechanical turk templates.

## News
TBA

# Quick Start
TBA

## Citation

If Modules is helpful to your research, please cite it as below.

```
@article{ku2023imagenhub,
  title={ImagenHub: Standardizing the evaluation of conditional image generation models},
  author={Max Ku, Tianle Li, Kai Zhang, Yujie Lu, Xingyu Fu, Wenwen Zhuang, Wenhu Chen},
  journal={arXiv preprint arXiv:2310.01596},
  year={2023}
}
```