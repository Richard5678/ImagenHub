# ImagenHub
[![arXiv](https://img.shields.io/badge/arXiv-2310.01596-b31b1b.svg)](https://arxiv.org/abs/2310.01596)

![](https://github.com/TIGER-AI-Lab/ImagenHub/blob/gh-pages/static/images/banner.png)

ImagenHub is a one-stop library to standardize the inference and evaluation of all the conditional image generation models.
* We define 7 prominent tasks and curate 7 high-quality evaluation datasets for each task. 
* We built a unified inference pipeline to ensure fair comparison. We currently support around 30 models.
* We designed two human evaluation scores, i.e. Semantic Consistency and Perceptual Quality, along with comprehensive guidelines to evaluate generated images. 
* We provide code for visualization, autometrics and Amazon mechanical turk templates.

<div align="center">
 ðŸ”¥ ðŸ”¥ ðŸ”¥ Check out our <a href = "https://tiger-ai-lab.github.io/ImagenHub/">[Project Page]</a> for more results and analysis!
</div>

## News
Coming Soon

# Quick Start
Coming Soon

# Contributing

_**Community contributions are encouraged!**_

Please refer to [CONTRIBUTING.md](CONTRIBUTING.md).

Feel free to open a PR if you think something is missing here. Always welcome feedback and suggestions. Just open an issue!

# Citation

Please kindly cite our paper if you use our code, data, models or results:

```bibtex
@article{ku2023imagenhub,
  title={ImagenHub: Standardizing the evaluation of conditional image generation models},
  author={Max Ku, Tianle Li, Kai Zhang, Yujie Lu, Xingyu Fu, Wenwen Zhuang, Wenhu Chen},
  journal={arXiv preprint arXiv:2310.01596},
  year={2023}
}
```